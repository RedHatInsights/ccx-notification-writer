@startuml
namespace main {
    class BrokerConfiguration << (S,Aquamarine) >> {
        + Address string
        + SecurityProtocol string
        + CertPath string
        + SaslMechanism string
        + SaslUsername string
        + SaslPassword string
        + Topic string
        + Group string
        + Enabled bool

    }
    class CliFlags << (S,Aquamarine) >> {
        + PerformDatabaseCleanup bool
        + PerformDatabaseInitialization bool
        + PerformDatabaseInitMigration bool
        + PerformDatabaseDropTables bool
        + CheckConnectionToKafka bool
        + ShowVersion bool
        + ShowAuthors bool
        + ShowConfiguration bool
        + PrintNewReportsForCleanup bool
        + PerformNewReportsCleanup bool
        + PrintOldReportsForCleanup bool
        + PerformOldReportsCleanup bool
        + MigrationInfo bool
        + MaxAge string
        + PerformMigrations string

    }
    class ConfigStruct << (S,Aquamarine) >> {
        + Broker BrokerConfiguration
        + Storage StorageConfiguration
        + Logging LoggingConfiguration
        + Metrics MetricsConfiguration

    }
    interface Consumer  {
        + Serve() 
        + Close() error
        + ProcessMessage(msg *sarama.ConsumerMessage) (RequestID, error)

    }
    class DBStorage << (S,Aquamarine) >> {
        - connection *sql.DB
        - dbDriverType DBDriver

        - insertReport(tx *sql.Tx, orgID OrgID, accountNumber AccountNumber, clusterName ClusterName, report ClusterReport, lastCheckedTime time.Time, kafkaOffset KafkaOffset) error

        + Close() error
        + WriteReportForCluster(orgID OrgID, accountNumber AccountNumber, clusterName ClusterName, report ClusterReport, lastCheckedTime time.Time, kafkaOffset KafkaOffset) error
        + DatabaseCleanup() error
        + DatabaseDropTables() error
        + DatabaseDropIndexes() error
        + GetDatabaseVersionInfo() (int, error)
        + DatabaseInitMigration() error
        + DatabaseInitialization() error
        + GetLatestKafkaOffset() (KafkaOffset, error)
        + PrintNewReports(maxAge string, query string, tableName string) error
        + PrintNewReportsForCleanup(maxAge string) error
        + PrintOldReportsForCleanup(maxAge string) error
        + Cleanup(maxAge string, statement string) (int, error)
        + CleanupNewReports(maxAge string) (int, error)
        + CleanupOldReports(maxAge string) (int, error)
        + Connection() *sql.DB

    }
    class IncomingMessage << (S,Aquamarine) >> {
        + Organization *OrgID
        + AccountNumber *AccountNumber
        + ClusterName *ClusterName
        + Report *Report
        + LastChecked string
        + Version SchemaVersion
        + RequestID RequestID

    }
    class KafkaConsumer << (S,Aquamarine) >> {
        - numberOfSuccessfullyConsumedMessages uint64
        - numberOfErrorsConsumingMessages uint64

        + Configuration BrokerConfiguration
        + ConsumerGroup sarama.ConsumerGroup
        + Storage Storage
        + Ready <font color=blue>chan</font> bool
        + Cancel context.CancelFunc

        + Serve() 
        + Setup( sarama.ConsumerGroupSession) error
        + Cleanup( sarama.ConsumerGroupSession) error
        + ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error
        + Close() error
        + GetNumberOfSuccessfullyConsumedMessages() uint64
        + GetNumberOfErrorsConsumingMessages() uint64
        + HandleMessage(msg *sarama.ConsumerMessage) 
        + ProcessMessage(msg *sarama.ConsumerMessage) (RequestID, error)

    }
    class LoggingConfiguration << (S,Aquamarine) >> {
        + Debug bool
        + LogLevel string

    }
    class MetricsConfiguration << (S,Aquamarine) >> {
        + Namespace string
        + Address string

    }
    interface Storage  {
        + Close() error
        + WriteReportForCluster(orgID OrgID, accountNumber AccountNumber, clusterName ClusterName, report ClusterReport, collectedAtTime time.Time, kafkaOffset KafkaOffset) error
        + DatabaseInitialization() error
        + DatabaseCleanup() error
        + DatabaseDropTables() error
        + DatabaseDropIndexes() error
        + DatabaseInitMigration() error
        + GetLatestKafkaOffset() (KafkaOffset, error)
        + PrintNewReportsForCleanup(maxAge string) error
        + CleanupNewReports(maxAge string) (int, error)
        + PrintOldReportsForCleanup(maxAge string) error
        + CleanupOldReports(maxAge string) (int, error)

    }
    class StorageConfiguration << (S,Aquamarine) >> {
        + Driver string
        + PGUsername string
        + PGPassword string
        + PGHost string
        + PGPort int
        + PGDBName string
        + PGParams string
        + LogSQLQueries bool

    }
    class main.AccountNumber << (T, #FF7700) >>  {
    }
    class main.ClusterName << (T, #FF7700) >>  {
    }
    class main.ClusterReport << (T, #FF7700) >>  {
    }
    class main.DBDriver << (T, #FF7700) >>  {
    }
    class main.KafkaOffset << (T, #FF7700) >>  {
    }
    class main.OrgID << (T, #FF7700) >>  {
    }
    class main.Report << (T, #FF7700) >>  {
    }
    class main.RequestID << (T, #FF7700) >>  {
    }
    class main.SchemaVersion << (T, #FF7700) >>  {
    }
    class "<font color=blue>map</font>[string]*json.RawMessage" as fontcolorbluemapfontstringjsonRawMessage {
        'This class was created so that we can correctly have an alias pointing to this name. Since it contains dots that can break namespaces
    }
}

"main.Storage" <|-- "main.DBStorage"
"main.Consumer" <|-- "main.KafkaConsumer"

"__builtin__.int" #.. "main.DBDriver"
"__builtin__.int64" #.. "main.KafkaOffset"
"__builtin__.string" #.. "main.ClusterName"
"__builtin__.string" #.. "main.ClusterReport"
"__builtin__.string" #.. "main.RequestID"
"__builtin__.uint32" #.. "main.AccountNumber"
"__builtin__.uint32" #.. "main.OrgID"
"__builtin__.uint8" #.. "main.SchemaVersion"
"main.fontcolorbluemapfontstringjsonRawMessage" #.. "main.Report"
@enduml
